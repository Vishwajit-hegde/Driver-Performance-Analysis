{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionTime v/s WaveNet Time",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishwajit-hegde/Driver-Performance-Analysis/blob/master/InceptionTime_v_s_WaveNet_Time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUcxFDn_LIuZ",
        "outputId": "ba784053-2046-460b-c7e9-583c69cb03c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from datetime import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import dates as md\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D,Conv2D,LSTM,GRU,Lambda\n",
        "from tensorflow.keras.layers import MaxPooling1D, Bidirectional, AveragePooling1D\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "from scipy import signal\n",
        "import gc\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNaKu5WULg9b",
        "outputId": "b622bff0-875d-491d-a846-e126494240ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df=pd.DataFrame()\n",
        "df1 = pd.DataFrame()\n",
        "os.chdir('/content/drive/My Drive/labelled_driver_data')\n",
        "for files in os.listdir(os.getcwd()):\n",
        "  print(files)\n",
        "  if files!='river4':\n",
        "    os.chdir('/content/drive/My Drive/labelled_driver_data/{}'.format(files))\n",
        "    for filename in os.listdir(os.getcwd()):\n",
        "        print(filename)\n",
        "        if 'acelerometro' in filename:\n",
        "          data = pd.read_csv(filename ,sep =',', header = 0 )\n",
        "          data.columns=['timestamp','uptimeNanos','X','Y','Z']\n",
        "          data['label'] = 0\n",
        "          data['device'] = 'acc'\n",
        "          data['uptimeNanos'] /= 1e9\n",
        "        elif 'giro' in filename:\n",
        "          data2 = pd.read_csv(filename ,sep =',', header = 0 )\n",
        "          data2.columns=['timestamp','uptimeNanos','X','Y','Z']\n",
        "          data2['label'] = 0\n",
        "          data2['device'] = 'gyr'\n",
        "          data2['uptimeNanos'] /= 1e9\n",
        "        elif 'ground' in filename:\n",
        "          labels = pd.read_csv(filename , sep=',')\n",
        "          labels[' inicio'] += data['uptimeNanos'][0]\n",
        "          labels[' fim'] += data['uptimeNanos'][0]\n",
        "\n",
        "    for event,start, end in labels.values:\n",
        "        l2 = data2.loc[data2.uptimeNanos.between(start, end),['label']].shape[0]\n",
        "        l1 = data.loc[data.uptimeNanos.between(start, end),['label']].shape[0]\n",
        "        data.loc[data.uptimeNanos.between(start, end),['label']] = [event]*l1\n",
        "        data2.loc[data2.uptimeNanos.between(start, end),['label']] = [event]*l2\n",
        "    df1 = pd.concat([data,data2], axis =1 , ignore_index=True)\n",
        "    df = df.append(df1)\n",
        "    del data, data2, labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "driver4\n",
            "acelerometro_terra.txt\n",
            "giroscopio_terra.txt\n",
            "groundTruth.txt\n",
            "aceleracaoLinear_terra.txt\n",
            "driver3\n",
            "acelerometro_terra.txt\n",
            "giroscopio_terra.txt\n",
            "groundTruth.txt\n",
            "aceleracaoLinear_terra.txt\n",
            "driver1\n",
            "acelerometro_terra.txt\n",
            "groundTruth.txt\n",
            "giroscopio_terra.txt\n",
            "aceleracaoLinear_terra.txt\n",
            "driver2\n",
            "acelerometro_terra.txt\n",
            "giroscopio_terra.txt\n",
            "groundTruth.txt\n",
            "aceleracaoLinear_terra.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1fgFh-FWF_w"
      },
      "source": [
        "df.columns =['timedate','time','X_acc','Y_acc','Z_acc','label','device','s','s1','X_gyr','Y_gyr','Z_gyr','s2','s3']\n",
        "df.timedate = pd.to_datetime(df.timedate)\n",
        "#df['label'] = df.label.apply(lambda x : 0 if x in ['evento_nao_agressivo',0] else 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oycbu1ptCD1M",
        "outputId": "45e8cea4-8920-4c72-e35c-0a0c52dea859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                 145435\n",
              "evento_nao_agressivo                2528\n",
              "aceleracao_agressiva                2202\n",
              "curva_direita_agressiva             1948\n",
              "curva_esquerda_agressiva            1946\n",
              "freada_agressiva                    1462\n",
              "troca_faixa_direita_agressiva        564\n",
              "troca_faixa_esquerda_agressiva       427\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SytV3jK0o46",
        "outputId": "14252ad2-f4d3-49d1-90c7-48f52af4cafe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['time'] = df.timedate.apply(lambda x : x.time())\n",
        "print('The sampling frequency in Hz is:',df.groupby('time').X_gyr.count().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sampling frequency in Hz is: 50.8816644993498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLpXwMzNf5hD",
        "outputId": "1d4fd7fc-bd25-42a0-dbb5-192673eff74e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('total time in min',(df.shape[0]/50)/60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time in min 52.17066666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWiuTrtgPyWr",
        "outputId": "f0a3c5cf-7165-4382-c3ad-96a29e2369d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.label.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.945378\n",
              "1    0.054622\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl_fUvufKp0h"
      },
      "source": [
        "df = df[['timedate','time','X_acc','Y_acc','Z_acc','X_gyr','Y_gyr','Z_gyr','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZN7XeLSMYRA",
        "outputId": "87bbcaaf-5dfb-4ffb-efd5-2e2496cd2ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timedate</th>\n",
              "      <th>time</th>\n",
              "      <th>X_acc</th>\n",
              "      <th>Y_acc</th>\n",
              "      <th>Z_acc</th>\n",
              "      <th>X_gyr</th>\n",
              "      <th>Y_gyr</th>\n",
              "      <th>Z_gyr</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-05-14 10:54:33</td>\n",
              "      <td>10:54:33</td>\n",
              "      <td>-0.161602</td>\n",
              "      <td>0.120174</td>\n",
              "      <td>9.596758</td>\n",
              "      <td>-0.070372</td>\n",
              "      <td>0.000844</td>\n",
              "      <td>0.029619</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-05-14 10:54:33</td>\n",
              "      <td>10:54:33</td>\n",
              "      <td>-0.122628</td>\n",
              "      <td>0.315638</td>\n",
              "      <td>9.425655</td>\n",
              "      <td>-0.058695</td>\n",
              "      <td>0.009130</td>\n",
              "      <td>0.024406</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-05-14 10:54:33</td>\n",
              "      <td>10:54:33</td>\n",
              "      <td>-0.178777</td>\n",
              "      <td>0.330180</td>\n",
              "      <td>9.445955</td>\n",
              "      <td>0.006625</td>\n",
              "      <td>-0.002283</td>\n",
              "      <td>-0.015018</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-05-14 10:54:33</td>\n",
              "      <td>10:54:33</td>\n",
              "      <td>0.016043</td>\n",
              "      <td>0.038759</td>\n",
              "      <td>9.528445</td>\n",
              "      <td>0.064933</td>\n",
              "      <td>0.033172</td>\n",
              "      <td>-0.040503</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-05-14 10:54:33</td>\n",
              "      <td>10:54:33</td>\n",
              "      <td>0.141716</td>\n",
              "      <td>-0.162492</td>\n",
              "      <td>9.756854</td>\n",
              "      <td>0.039454</td>\n",
              "      <td>-0.013078</td>\n",
              "      <td>-0.007681</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             timedate      time     X_acc  ...     Y_gyr     Z_gyr  label\n",
              "0 2016-05-14 10:54:33  10:54:33 -0.161602  ...  0.000844  0.029619      0\n",
              "1 2016-05-14 10:54:33  10:54:33 -0.122628  ...  0.009130  0.024406      0\n",
              "2 2016-05-14 10:54:33  10:54:33 -0.178777  ... -0.002283 -0.015018      0\n",
              "3 2016-05-14 10:54:33  10:54:33  0.016043  ...  0.033172 -0.040503      0\n",
              "4 2016-05-14 10:54:33  10:54:33  0.141716  ... -0.013078 -0.007681      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wluSclYino2i"
      },
      "source": [
        "df.dropna(inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paVYzhhdaJg_"
      },
      "source": [
        "dftrain = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWq2wcLOycv5"
      },
      "source": [
        "#Y is lateraal \n",
        "#X is longitudinal\n",
        "#Z is  vertical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOU1Alb3ad2e"
      },
      "source": [
        "def train_dataset(series,window_size, batch_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((series))\n",
        "    ds = ds.window(window_size, shift=20, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.shuffle(10000).map(lambda window: (window[:,:-1], window[50,-1:]))\n",
        "    #ds = ds.batch(batch_size).prefetch(1)\n",
        "    return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE6jPPvFbhLO"
      },
      "source": [
        "train= train_dataset(dftrain[['X_acc','Y_acc','X_gyr','Y_gyr','Z_gyr','label']].values,100,128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tt9xy6bz0Gx"
      },
      "source": [
        "X=[]\n",
        "y=[]\n",
        "for i,j in train:\n",
        "  X.append(i.numpy())\n",
        "  y.append(j.numpy())\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw2ayLgH3sdg"
      },
      "source": [
        "def get_unit(x):\n",
        "  x1 = Conv1D(16, 1, padding='same', activation='relu')(x)\n",
        "\n",
        "  x2 = Conv1D(16, 1, padding='same', activation='relu')(x)\n",
        "  x2 = Conv1D(32, 3, padding='same', activation='relu')(x2)\n",
        "\n",
        "  x3 = Conv1D(16, 1, padding='same', activation='relu')(x)\n",
        "  x3 = Conv1D(32, 5, padding='same', activation='relu')(x3)\n",
        "\n",
        "  output  = tf.concat([x1,x2,x3,x], axis =  -1)\n",
        "  return output\n",
        "  \n",
        "def create_incep(n):\n",
        "    history_seq = Input(shape=(100, n))\n",
        "    x = history_seq\n",
        "    x = Conv1D(16, 1, activation='relu')(x)\n",
        "    x = AveragePooling1D(2)(x)\n",
        "    x = Conv1D(16, 1, activation='relu')(x)\n",
        "    x = AveragePooling1D(2)(x)\n",
        "    x = get_unit(x)\n",
        "    x = AveragePooling1D(2)(x)\n",
        "    x = get_unit(x)\n",
        "    x = Conv1D(16, 1, padding='same', activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(50, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    Incep = Model(history_seq,x)\n",
        "    Incep.compile(tf.keras.optimizers.Adam(lr = 1e-4), loss='binary_crossentropy', metrics =METRICS)\n",
        "    return Incep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW3zSxAJ-21x",
        "outputId": "6d6849dc-38f4-42a0-e3f3-bb1422869668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Incep = create_incep(5)\n",
        "Incep.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           [(None, 100, 5)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_113 (Conv1D)             (None, 100, 16)      96          input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_27 (AveragePo (None, 50, 16)       0           conv1d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_114 (Conv1D)             (None, 50, 16)       272         average_pooling1d_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_28 (AveragePo (None, 25, 16)       0           conv1d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_116 (Conv1D)             (None, 25, 16)       272         average_pooling1d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_118 (Conv1D)             (None, 25, 16)       272         average_pooling1d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_115 (Conv1D)             (None, 25, 16)       272         average_pooling1d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_117 (Conv1D)             (None, 25, 32)       1568        conv1d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_119 (Conv1D)             (None, 25, 32)       2592        conv1d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_14 (TensorFl [(None, 25, 96)]     0           conv1d_115[0][0]                 \n",
            "                                                                 conv1d_117[0][0]                 \n",
            "                                                                 conv1d_119[0][0]                 \n",
            "                                                                 average_pooling1d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_29 (AveragePo (None, 12, 96)       0           tf_op_layer_concat_14[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_121 (Conv1D)             (None, 12, 16)       1552        average_pooling1d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_123 (Conv1D)             (None, 12, 16)       1552        average_pooling1d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_120 (Conv1D)             (None, 12, 16)       1552        average_pooling1d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_122 (Conv1D)             (None, 12, 32)       1568        conv1d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_124 (Conv1D)             (None, 12, 32)       2592        conv1d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_15 (TensorFl [(None, 12, 176)]    0           conv1d_120[0][0]                 \n",
            "                                                                 conv1d_122[0][0]                 \n",
            "                                                                 conv1d_124[0][0]                 \n",
            "                                                                 average_pooling1d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_125 (Conv1D)             (None, 12, 16)       2832        tf_op_layer_concat_15[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 192)          0           conv1d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 50)           9650        flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 50)           0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            51          dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,693\n",
            "Trainable params: 26,693\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A1V3ObmnoBm"
      },
      "source": [
        "def create_model(n, n_filters =32, filter_width = 10 , dilation_rates =[2**i for i in range(8)] * 2 ):\n",
        "\n",
        "  # define an input history series and pass it through a stack of dilated causal convolution blocks. \n",
        "  history_seq = Input(shape=(100, n))\n",
        "  x = history_seq\n",
        "\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      # preprocessing - equivalent to time-distributed dense\n",
        "      x = Conv1D(16, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter convolution\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gating convolution\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # multiply filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(16, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      # collect skip connections\n",
        "      skips.append(z)\n",
        "\n",
        "  # add all skip connection outputs \n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  # final time-distributed dense layers \n",
        "  out = Conv1D(100, 1, padding='same')(out)\n",
        "  out = Activation('relu')(out)\n",
        "  out = Dropout(.2)(out)\n",
        "  out = Conv1D(1,1, padding='same')(out)\n",
        "  out = Flatten()(out)\n",
        "  out = Dense(100, activation='relu')(out)\n",
        "  out = Dropout(.3)(out)\n",
        "  out = Dense(10, activation='relu')(out)\n",
        "  out = Dense(1, activation='sigmoid')(out)\n",
        "\n",
        "  model = Model(history_seq, out)\n",
        "  model.compile(tf.keras.optimizers.Adam(lr = 1e-4), loss='binary_crossentropy', metrics =METRICS)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko14UipbHwoz"
      },
      "source": [
        "weight_for_0 = (1 / 110178)*(116512)/2.0\n",
        "weight_for_1 = (1 / 6334)*(116512)/2.0\n",
        "\n",
        "class_weight = {0: 1, 1: 2}\n",
        "METRICS = [\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold =0.5),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc')\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJsCqUAng_k6",
        "outputId": "25685f88-e1bd-4300-89b8-1cfecdae6e86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "auc =[]\n",
        "val_auc =[]\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.25, random_state=47)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  model = create_incep(5)\n",
        "  history = model.fit(X_train, y_train,batch_size =64,  epochs =50, validation_data=(X_test, y_test),verbose = 1,validation_batch_size=64,callbacks =[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)])\n",
        "  if history.history['accuracy'][-7]> 0.95 and history.history['val_accuracy'][-7] >0.95:\n",
        "    print('The model is better than a simple constant model for sure:')\n",
        "    auc.append(history.history['auc'][-7])\n",
        "    val_auc.append(history.history['val_auc'][-7])\n",
        "  else:\n",
        "    print('This prediction is garbage')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 0.5467 - tp: 16.0000 - fp: 209.0000 - tn: 5334.0000 - fn: 306.0000 - accuracy: 0.9122 - precision: 0.0711 - recall: 0.0497 - auc: 0.3143 - val_loss: 0.4217 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1114\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.3547 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5543.0000 - fn: 322.0000 - accuracy: 0.9451 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1671 - val_loss: 0.3238 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1319\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.2617 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5543.0000 - fn: 322.0000 - accuracy: 0.9451 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3555 - val_loss: 0.2170 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5400\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1770 - tp: 25.0000 - fp: 16.0000 - tn: 5527.0000 - fn: 297.0000 - accuracy: 0.9466 - precision: 0.6098 - recall: 0.0776 - auc: 0.7773 - val_loss: 0.1336 - val_tp: 31.0000 - val_fp: 6.0000 - val_tn: 1843.0000 - val_fn: 76.0000 - val_accuracy: 0.9581 - val_precision: 0.8378 - val_recall: 0.2897 - val_auc: 0.9125\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1387 - tp: 102.0000 - fp: 28.0000 - tn: 5515.0000 - fn: 220.0000 - accuracy: 0.9577 - precision: 0.7846 - recall: 0.3168 - auc: 0.8779 - val_loss: 0.1157 - val_tp: 48.0000 - val_fp: 11.0000 - val_tn: 1838.0000 - val_fn: 59.0000 - val_accuracy: 0.9642 - val_precision: 0.8136 - val_recall: 0.4486 - val_auc: 0.9303\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.1260 - tp: 125.0000 - fp: 45.0000 - tn: 5498.0000 - fn: 197.0000 - accuracy: 0.9587 - precision: 0.7353 - recall: 0.3882 - auc: 0.9058 - val_loss: 0.1110 - val_tp: 59.0000 - val_fp: 19.0000 - val_tn: 1830.0000 - val_fn: 48.0000 - val_accuracy: 0.9657 - val_precision: 0.7564 - val_recall: 0.5514 - val_auc: 0.9354\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1218 - tp: 137.0000 - fp: 43.0000 - tn: 5500.0000 - fn: 185.0000 - accuracy: 0.9611 - precision: 0.7611 - recall: 0.4255 - auc: 0.9052 - val_loss: 0.1074 - val_tp: 63.0000 - val_fp: 21.0000 - val_tn: 1828.0000 - val_fn: 44.0000 - val_accuracy: 0.9668 - val_precision: 0.7500 - val_recall: 0.5888 - val_auc: 0.9395\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.1157 - tp: 156.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 166.0000 - accuracy: 0.9642 - precision: 0.7800 - recall: 0.4845 - auc: 0.9151 - val_loss: 0.1019 - val_tp: 53.0000 - val_fp: 10.0000 - val_tn: 1839.0000 - val_fn: 54.0000 - val_accuracy: 0.9673 - val_precision: 0.8413 - val_recall: 0.4953 - val_auc: 0.9396\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1138 - tp: 153.0000 - fp: 45.0000 - tn: 5498.0000 - fn: 169.0000 - accuracy: 0.9635 - precision: 0.7727 - recall: 0.4752 - auc: 0.9196 - val_loss: 0.0999 - val_tp: 62.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 45.0000 - val_accuracy: 0.9698 - val_precision: 0.8158 - val_recall: 0.5794 - val_auc: 0.9427\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1106 - tp: 159.0000 - fp: 46.0000 - tn: 5497.0000 - fn: 163.0000 - accuracy: 0.9644 - precision: 0.7756 - recall: 0.4938 - auc: 0.9221 - val_loss: 0.0989 - val_tp: 55.0000 - val_fp: 6.0000 - val_tn: 1843.0000 - val_fn: 52.0000 - val_accuracy: 0.9703 - val_precision: 0.9016 - val_recall: 0.5140 - val_auc: 0.9428\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1090 - tp: 168.0000 - fp: 42.0000 - tn: 5501.0000 - fn: 154.0000 - accuracy: 0.9666 - precision: 0.8000 - recall: 0.5217 - auc: 0.9161 - val_loss: 0.0975 - val_tp: 66.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 41.0000 - val_accuracy: 0.9703 - val_precision: 0.7952 - val_recall: 0.6168 - val_auc: 0.9450\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1072 - tp: 166.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 156.0000 - accuracy: 0.9659 - precision: 0.7905 - recall: 0.5155 - auc: 0.9266 - val_loss: 0.0956 - val_tp: 61.0000 - val_fp: 11.0000 - val_tn: 1838.0000 - val_fn: 46.0000 - val_accuracy: 0.9709 - val_precision: 0.8472 - val_recall: 0.5701 - val_auc: 0.9442\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1066 - tp: 169.0000 - fp: 50.0000 - tn: 5493.0000 - fn: 153.0000 - accuracy: 0.9654 - precision: 0.7717 - recall: 0.5248 - auc: 0.9248 - val_loss: 0.0961 - val_tp: 59.0000 - val_fp: 8.0000 - val_tn: 1841.0000 - val_fn: 48.0000 - val_accuracy: 0.9714 - val_precision: 0.8806 - val_recall: 0.5514 - val_auc: 0.9446\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1068 - tp: 173.0000 - fp: 42.0000 - tn: 5501.0000 - fn: 149.0000 - accuracy: 0.9674 - precision: 0.8047 - recall: 0.5373 - auc: 0.9253 - val_loss: 0.0955 - val_tp: 61.0000 - val_fp: 6.0000 - val_tn: 1843.0000 - val_fn: 46.0000 - val_accuracy: 0.9734 - val_precision: 0.9104 - val_recall: 0.5701 - val_auc: 0.9445\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1049 - tp: 180.0000 - fp: 46.0000 - tn: 5497.0000 - fn: 142.0000 - accuracy: 0.9679 - precision: 0.7965 - recall: 0.5590 - auc: 0.9307 - val_loss: 0.0957 - val_tp: 62.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 45.0000 - val_accuracy: 0.9709 - val_precision: 0.8378 - val_recall: 0.5794 - val_auc: 0.9461\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1044 - tp: 167.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 155.0000 - accuracy: 0.9656 - precision: 0.7804 - recall: 0.5186 - auc: 0.9338 - val_loss: 0.0948 - val_tp: 66.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 41.0000 - val_accuracy: 0.9698 - val_precision: 0.7857 - val_recall: 0.6168 - val_auc: 0.9442\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1015 - tp: 179.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 143.0000 - accuracy: 0.9676 - precision: 0.7920 - recall: 0.5559 - auc: 0.9363 - val_loss: 0.0944 - val_tp: 64.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 43.0000 - val_accuracy: 0.9709 - val_precision: 0.8205 - val_recall: 0.5981 - val_auc: 0.9482\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1016 - tp: 179.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 143.0000 - accuracy: 0.9681 - precision: 0.8027 - recall: 0.5559 - auc: 0.9343 - val_loss: 0.0955 - val_tp: 66.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 41.0000 - val_accuracy: 0.9703 - val_precision: 0.7952 - val_recall: 0.6168 - val_auc: 0.9451\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1021 - tp: 181.0000 - fp: 43.0000 - tn: 5500.0000 - fn: 141.0000 - accuracy: 0.9686 - precision: 0.8080 - recall: 0.5621 - auc: 0.9320 - val_loss: 0.0944 - val_tp: 65.0000 - val_fp: 16.0000 - val_tn: 1833.0000 - val_fn: 42.0000 - val_accuracy: 0.9703 - val_precision: 0.8025 - val_recall: 0.6075 - val_auc: 0.9450\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1003 - tp: 186.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 136.0000 - accuracy: 0.9688 - precision: 0.7983 - recall: 0.5776 - auc: 0.9371 - val_loss: 0.0932 - val_tp: 65.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 42.0000 - val_accuracy: 0.9714 - val_precision: 0.8228 - val_recall: 0.6075 - val_auc: 0.9459\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1014 - tp: 182.0000 - fp: 42.0000 - tn: 5501.0000 - fn: 140.0000 - accuracy: 0.9690 - precision: 0.8125 - recall: 0.5652 - auc: 0.9306 - val_loss: 0.0935 - val_tp: 64.0000 - val_fp: 8.0000 - val_tn: 1841.0000 - val_fn: 43.0000 - val_accuracy: 0.9739 - val_precision: 0.8889 - val_recall: 0.5981 - val_auc: 0.9476\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0989 - tp: 184.0000 - fp: 42.0000 - tn: 5501.0000 - fn: 138.0000 - accuracy: 0.9693 - precision: 0.8142 - recall: 0.5714 - auc: 0.9361 - val_loss: 0.0929 - val_tp: 67.0000 - val_fp: 16.0000 - val_tn: 1833.0000 - val_fn: 40.0000 - val_accuracy: 0.9714 - val_precision: 0.8072 - val_recall: 0.6262 - val_auc: 0.9471\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0999 - tp: 183.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 139.0000 - accuracy: 0.9688 - precision: 0.8062 - recall: 0.5683 - auc: 0.9378 - val_loss: 0.0930 - val_tp: 65.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 42.0000 - val_accuracy: 0.9724 - val_precision: 0.8442 - val_recall: 0.6075 - val_auc: 0.9483\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0980 - tp: 185.0000 - fp: 49.0000 - tn: 5494.0000 - fn: 137.0000 - accuracy: 0.9683 - precision: 0.7906 - recall: 0.5745 - auc: 0.9386 - val_loss: 0.0943 - val_tp: 71.0000 - val_fp: 25.0000 - val_tn: 1824.0000 - val_fn: 36.0000 - val_accuracy: 0.9688 - val_precision: 0.7396 - val_recall: 0.6636 - val_auc: 0.9465\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0978 - tp: 183.0000 - fp: 42.0000 - tn: 5501.0000 - fn: 139.0000 - accuracy: 0.9691 - precision: 0.8133 - recall: 0.5683 - auc: 0.9428 - val_loss: 0.0925 - val_tp: 63.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 44.0000 - val_accuracy: 0.9714 - val_precision: 0.8400 - val_recall: 0.5888 - val_auc: 0.9480\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0980 - tp: 188.0000 - fp: 48.0000 - tn: 5495.0000 - fn: 134.0000 - accuracy: 0.9690 - precision: 0.7966 - recall: 0.5839 - auc: 0.9343 - val_loss: 0.0933 - val_tp: 64.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 43.0000 - val_accuracy: 0.9719 - val_precision: 0.8421 - val_recall: 0.5981 - val_auc: 0.9483\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0961 - tp: 179.0000 - fp: 43.0000 - tn: 5500.0000 - fn: 143.0000 - accuracy: 0.9683 - precision: 0.8063 - recall: 0.5559 - auc: 0.9416 - val_loss: 0.0935 - val_tp: 68.0000 - val_fp: 19.0000 - val_tn: 1830.0000 - val_fn: 39.0000 - val_accuracy: 0.9703 - val_precision: 0.7816 - val_recall: 0.6355 - val_auc: 0.9479\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0976 - tp: 182.0000 - fp: 50.0000 - tn: 5493.0000 - fn: 140.0000 - accuracy: 0.9676 - precision: 0.7845 - recall: 0.5652 - auc: 0.9405 - val_loss: 0.0959 - val_tp: 72.0000 - val_fp: 30.0000 - val_tn: 1819.0000 - val_fn: 35.0000 - val_accuracy: 0.9668 - val_precision: 0.7059 - val_recall: 0.6729 - val_auc: 0.9527\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0966 - tp: 187.0000 - fp: 42.0000 - tn: 5501.0000 - fn: 135.0000 - accuracy: 0.9698 - precision: 0.8166 - recall: 0.5807 - auc: 0.9395 - val_loss: 0.0924 - val_tp: 68.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 39.0000 - val_accuracy: 0.9709 - val_precision: 0.7907 - val_recall: 0.6355 - val_auc: 0.9483\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0952 - tp: 190.0000 - fp: 43.0000 - tn: 5500.0000 - fn: 132.0000 - accuracy: 0.9702 - precision: 0.8155 - recall: 0.5901 - auc: 0.9445 - val_loss: 0.0921 - val_tp: 68.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 39.0000 - val_accuracy: 0.9714 - val_precision: 0.8000 - val_recall: 0.6355 - val_auc: 0.9491\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0949 - tp: 188.0000 - fp: 39.0000 - tn: 5504.0000 - fn: 134.0000 - accuracy: 0.9705 - precision: 0.8282 - recall: 0.5839 - auc: 0.9437 - val_loss: 0.0915 - val_tp: 64.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 43.0000 - val_accuracy: 0.9709 - val_precision: 0.8205 - val_recall: 0.5981 - val_auc: 0.9481\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0939 - tp: 188.0000 - fp: 43.0000 - tn: 5500.0000 - fn: 134.0000 - accuracy: 0.9698 - precision: 0.8139 - recall: 0.5839 - auc: 0.9470 - val_loss: 0.0931 - val_tp: 69.0000 - val_fp: 20.0000 - val_tn: 1829.0000 - val_fn: 38.0000 - val_accuracy: 0.9703 - val_precision: 0.7753 - val_recall: 0.6449 - val_auc: 0.9507\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0949 - tp: 196.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 126.0000 - accuracy: 0.9710 - precision: 0.8167 - recall: 0.6087 - auc: 0.9467 - val_loss: 0.0925 - val_tp: 71.0000 - val_fp: 21.0000 - val_tn: 1828.0000 - val_fn: 36.0000 - val_accuracy: 0.9709 - val_precision: 0.7717 - val_recall: 0.6636 - val_auc: 0.9531\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0924 - tp: 188.0000 - fp: 39.0000 - tn: 5504.0000 - fn: 134.0000 - accuracy: 0.9705 - precision: 0.8282 - recall: 0.5839 - auc: 0.9492 - val_loss: 0.0921 - val_tp: 69.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 38.0000 - val_accuracy: 0.9719 - val_precision: 0.8023 - val_recall: 0.6449 - val_auc: 0.9513\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0925 - tp: 193.0000 - fp: 35.0000 - tn: 5508.0000 - fn: 129.0000 - accuracy: 0.9720 - precision: 0.8465 - recall: 0.5994 - auc: 0.9464 - val_loss: 0.0940 - val_tp: 71.0000 - val_fp: 28.0000 - val_tn: 1821.0000 - val_fn: 36.0000 - val_accuracy: 0.9673 - val_precision: 0.7172 - val_recall: 0.6636 - val_auc: 0.9547\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0909 - tp: 197.0000 - fp: 46.0000 - tn: 5497.0000 - fn: 125.0000 - accuracy: 0.9708 - precision: 0.8107 - recall: 0.6118 - auc: 0.9512 - val_loss: 0.0947 - val_tp: 71.0000 - val_fp: 30.0000 - val_tn: 1819.0000 - val_fn: 36.0000 - val_accuracy: 0.9663 - val_precision: 0.7030 - val_recall: 0.6636 - val_auc: 0.9504\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0908 - tp: 190.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 132.0000 - accuracy: 0.9695 - precision: 0.8017 - recall: 0.5901 - auc: 0.9519 - val_loss: 0.0927 - val_tp: 72.0000 - val_fp: 25.0000 - val_tn: 1824.0000 - val_fn: 35.0000 - val_accuracy: 0.9693 - val_precision: 0.7423 - val_recall: 0.6729 - val_auc: 0.9549\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0890 - tp: 196.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 126.0000 - accuracy: 0.9710 - precision: 0.8167 - recall: 0.6087 - auc: 0.9565 - val_loss: 0.0912 - val_tp: 64.0000 - val_fp: 13.0000 - val_tn: 1836.0000 - val_fn: 43.0000 - val_accuracy: 0.9714 - val_precision: 0.8312 - val_recall: 0.5981 - val_auc: 0.9531\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0886 - tp: 200.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 122.0000 - accuracy: 0.9712 - precision: 0.8097 - recall: 0.6211 - auc: 0.9529 - val_loss: 0.0953 - val_tp: 72.0000 - val_fp: 33.0000 - val_tn: 1816.0000 - val_fn: 35.0000 - val_accuracy: 0.9652 - val_precision: 0.6857 - val_recall: 0.6729 - val_auc: 0.9548\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0908 - tp: 202.0000 - fp: 40.0000 - tn: 5503.0000 - fn: 120.0000 - accuracy: 0.9727 - precision: 0.8347 - recall: 0.6273 - auc: 0.9540 - val_loss: 0.0933 - val_tp: 64.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 43.0000 - val_accuracy: 0.9719 - val_precision: 0.8421 - val_recall: 0.5981 - val_auc: 0.9520\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0904 - tp: 193.0000 - fp: 39.0000 - tn: 5504.0000 - fn: 129.0000 - accuracy: 0.9714 - precision: 0.8319 - recall: 0.5994 - auc: 0.9463 - val_loss: 0.0914 - val_tp: 69.0000 - val_fp: 16.0000 - val_tn: 1833.0000 - val_fn: 38.0000 - val_accuracy: 0.9724 - val_precision: 0.8118 - val_recall: 0.6449 - val_auc: 0.9528\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0891 - tp: 195.0000 - fp: 38.0000 - tn: 5505.0000 - fn: 127.0000 - accuracy: 0.9719 - precision: 0.8369 - recall: 0.6056 - auc: 0.9534 - val_loss: 0.0901 - val_tp: 65.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 42.0000 - val_accuracy: 0.9714 - val_precision: 0.8228 - val_recall: 0.6075 - val_auc: 0.9517\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0882 - tp: 200.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 122.0000 - accuracy: 0.9712 - precision: 0.8097 - recall: 0.6211 - auc: 0.9550 - val_loss: 0.0920 - val_tp: 71.0000 - val_fp: 29.0000 - val_tn: 1820.0000 - val_fn: 36.0000 - val_accuracy: 0.9668 - val_precision: 0.7100 - val_recall: 0.6636 - val_auc: 0.9570\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0887 - tp: 202.0000 - fp: 39.0000 - tn: 5504.0000 - fn: 120.0000 - accuracy: 0.9729 - precision: 0.8382 - recall: 0.6273 - auc: 0.9532 - val_loss: 0.0904 - val_tp: 68.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 39.0000 - val_accuracy: 0.9729 - val_precision: 0.8293 - val_recall: 0.6355 - val_auc: 0.9525\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0878 - tp: 204.0000 - fp: 37.0000 - tn: 5506.0000 - fn: 118.0000 - accuracy: 0.9736 - precision: 0.8465 - recall: 0.6335 - auc: 0.9536 - val_loss: 0.0934 - val_tp: 71.0000 - val_fp: 28.0000 - val_tn: 1821.0000 - val_fn: 36.0000 - val_accuracy: 0.9673 - val_precision: 0.7172 - val_recall: 0.6636 - val_auc: 0.9526\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0885 - tp: 204.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 118.0000 - accuracy: 0.9719 - precision: 0.8127 - recall: 0.6335 - auc: 0.9534 - val_loss: 0.0914 - val_tp: 68.0000 - val_fp: 16.0000 - val_tn: 1833.0000 - val_fn: 39.0000 - val_accuracy: 0.9719 - val_precision: 0.8095 - val_recall: 0.6355 - val_auc: 0.9525\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0854 - tp: 199.0000 - fp: 35.0000 - tn: 5508.0000 - fn: 123.0000 - accuracy: 0.9731 - precision: 0.8504 - recall: 0.6180 - auc: 0.9547 - val_loss: 0.0928 - val_tp: 72.0000 - val_fp: 29.0000 - val_tn: 1820.0000 - val_fn: 35.0000 - val_accuracy: 0.9673 - val_precision: 0.7129 - val_recall: 0.6729 - val_auc: 0.9581\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0860 - tp: 205.0000 - fp: 43.0000 - tn: 5500.0000 - fn: 117.0000 - accuracy: 0.9727 - precision: 0.8266 - recall: 0.6366 - auc: 0.9562 - val_loss: 0.0914 - val_tp: 66.0000 - val_fp: 11.0000 - val_tn: 1838.0000 - val_fn: 41.0000 - val_accuracy: 0.9734 - val_precision: 0.8571 - val_recall: 0.6168 - val_auc: 0.9538\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0865 - tp: 208.0000 - fp: 41.0000 - tn: 5502.0000 - fn: 114.0000 - accuracy: 0.9736 - precision: 0.8353 - recall: 0.6460 - auc: 0.9561 - val_loss: 0.0942 - val_tp: 72.0000 - val_fp: 32.0000 - val_tn: 1817.0000 - val_fn: 35.0000 - val_accuracy: 0.9657 - val_precision: 0.6923 - val_recall: 0.6729 - val_auc: 0.9569\n",
            "The model is better than a simple constant model for sure:\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 0.5153 - tp: 79.0000 - fp: 113.0000 - tn: 7279.0000 - fn: 350.0000 - accuracy: 0.9408 - precision: 0.4115 - recall: 0.1841 - auc: 0.5415 - val_loss: 0.3972 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0884\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.3621 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5543.0000 - fn: 322.0000 - accuracy: 0.9451 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1237 - val_loss: 0.3185 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1329\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.2690 - tp: 1.0000 - fp: 0.0000e+00 - tn: 5543.0000 - fn: 321.0000 - accuracy: 0.9453 - precision: 1.0000 - recall: 0.0031 - auc: 0.3212 - val_loss: 0.2221 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4322\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1769 - tp: 43.0000 - fp: 20.0000 - tn: 5523.0000 - fn: 279.0000 - accuracy: 0.9490 - precision: 0.6825 - recall: 0.1335 - auc: 0.7694 - val_loss: 0.1413 - val_tp: 20.0000 - val_fp: 5.0000 - val_tn: 1844.0000 - val_fn: 87.0000 - val_accuracy: 0.9530 - val_precision: 0.8000 - val_recall: 0.1869 - val_auc: 0.8944\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1324 - tp: 107.0000 - fp: 42.0000 - tn: 5501.0000 - fn: 215.0000 - accuracy: 0.9562 - precision: 0.7181 - recall: 0.3323 - auc: 0.8986 - val_loss: 0.1156 - val_tp: 51.0000 - val_fp: 9.0000 - val_tn: 1840.0000 - val_fn: 56.0000 - val_accuracy: 0.9668 - val_precision: 0.8500 - val_recall: 0.4766 - val_auc: 0.9219\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1217 - tp: 145.0000 - fp: 56.0000 - tn: 5487.0000 - fn: 177.0000 - accuracy: 0.9603 - precision: 0.7214 - recall: 0.4503 - auc: 0.8976 - val_loss: 0.1097 - val_tp: 50.0000 - val_fp: 6.0000 - val_tn: 1843.0000 - val_fn: 57.0000 - val_accuracy: 0.9678 - val_precision: 0.8929 - val_recall: 0.4673 - val_auc: 0.9322\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1140 - tp: 154.0000 - fp: 51.0000 - tn: 5492.0000 - fn: 168.0000 - accuracy: 0.9627 - precision: 0.7512 - recall: 0.4783 - auc: 0.9166 - val_loss: 0.1062 - val_tp: 57.0000 - val_fp: 9.0000 - val_tn: 1840.0000 - val_fn: 50.0000 - val_accuracy: 0.9698 - val_precision: 0.8636 - val_recall: 0.5327 - val_auc: 0.9219\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1130 - tp: 166.0000 - fp: 59.0000 - tn: 5484.0000 - fn: 156.0000 - accuracy: 0.9633 - precision: 0.7378 - recall: 0.5155 - auc: 0.9155 - val_loss: 0.1049 - val_tp: 59.0000 - val_fp: 15.0000 - val_tn: 1834.0000 - val_fn: 48.0000 - val_accuracy: 0.9678 - val_precision: 0.7973 - val_recall: 0.5514 - val_auc: 0.9284\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1106 - tp: 178.0000 - fp: 58.0000 - tn: 5485.0000 - fn: 144.0000 - accuracy: 0.9656 - precision: 0.7542 - recall: 0.5528 - auc: 0.9164 - val_loss: 0.1202 - val_tp: 34.0000 - val_fp: 4.0000 - val_tn: 1845.0000 - val_fn: 73.0000 - val_accuracy: 0.9606 - val_precision: 0.8947 - val_recall: 0.3178 - val_auc: 0.9258\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1115 - tp: 169.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 153.0000 - accuracy: 0.9650 - precision: 0.7647 - recall: 0.5248 - auc: 0.9192 - val_loss: 0.1047 - val_tp: 57.0000 - val_fp: 8.0000 - val_tn: 1841.0000 - val_fn: 50.0000 - val_accuracy: 0.9703 - val_precision: 0.8769 - val_recall: 0.5327 - val_auc: 0.9231\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1117 - tp: 168.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 154.0000 - accuracy: 0.9647 - precision: 0.7602 - recall: 0.5217 - auc: 0.9177 - val_loss: 0.1034 - val_tp: 59.0000 - val_fp: 13.0000 - val_tn: 1836.0000 - val_fn: 48.0000 - val_accuracy: 0.9688 - val_precision: 0.8194 - val_recall: 0.5514 - val_auc: 0.9258\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1103 - tp: 173.0000 - fp: 66.0000 - tn: 5477.0000 - fn: 149.0000 - accuracy: 0.9633 - precision: 0.7238 - recall: 0.5373 - auc: 0.9126 - val_loss: 0.1082 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 1842.0000 - val_fn: 57.0000 - val_accuracy: 0.9673 - val_precision: 0.8772 - val_recall: 0.4673 - val_auc: 0.9316\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1096 - tp: 176.0000 - fp: 55.0000 - tn: 5488.0000 - fn: 146.0000 - accuracy: 0.9657 - precision: 0.7619 - recall: 0.5466 - auc: 0.9139 - val_loss: 0.1048 - val_tp: 56.0000 - val_fp: 8.0000 - val_tn: 1841.0000 - val_fn: 51.0000 - val_accuracy: 0.9698 - val_precision: 0.8750 - val_recall: 0.5234 - val_auc: 0.9256\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1061 - tp: 186.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 136.0000 - accuracy: 0.9679 - precision: 0.7815 - recall: 0.5776 - auc: 0.9277 - val_loss: 0.1025 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 47.0000 - val_accuracy: 0.9673 - val_precision: 0.7792 - val_recall: 0.5607 - val_auc: 0.9364\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1053 - tp: 180.0000 - fp: 54.0000 - tn: 5489.0000 - fn: 142.0000 - accuracy: 0.9666 - precision: 0.7692 - recall: 0.5590 - auc: 0.9256 - val_loss: 0.1021 - val_tp: 60.0000 - val_fp: 13.0000 - val_tn: 1836.0000 - val_fn: 47.0000 - val_accuracy: 0.9693 - val_precision: 0.8219 - val_recall: 0.5607 - val_auc: 0.9346\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1055 - tp: 181.0000 - fp: 58.0000 - tn: 5485.0000 - fn: 141.0000 - accuracy: 0.9661 - precision: 0.7573 - recall: 0.5621 - auc: 0.9262 - val_loss: 0.1036 - val_tp: 55.0000 - val_fp: 10.0000 - val_tn: 1839.0000 - val_fn: 52.0000 - val_accuracy: 0.9683 - val_precision: 0.8462 - val_recall: 0.5140 - val_auc: 0.9329\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1059 - tp: 182.0000 - fp: 59.0000 - tn: 5484.0000 - fn: 140.0000 - accuracy: 0.9661 - precision: 0.7552 - recall: 0.5652 - auc: 0.9290 - val_loss: 0.1025 - val_tp: 59.0000 - val_fp: 13.0000 - val_tn: 1836.0000 - val_fn: 48.0000 - val_accuracy: 0.9688 - val_precision: 0.8194 - val_recall: 0.5514 - val_auc: 0.9307\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1035 - tp: 184.0000 - fp: 54.0000 - tn: 5489.0000 - fn: 138.0000 - accuracy: 0.9673 - precision: 0.7731 - recall: 0.5714 - auc: 0.9287 - val_loss: 0.1047 - val_tp: 55.0000 - val_fp: 8.0000 - val_tn: 1841.0000 - val_fn: 52.0000 - val_accuracy: 0.9693 - val_precision: 0.8730 - val_recall: 0.5140 - val_auc: 0.9312\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1048 - tp: 184.0000 - fp: 58.0000 - tn: 5485.0000 - fn: 138.0000 - accuracy: 0.9666 - precision: 0.7603 - recall: 0.5714 - auc: 0.9273 - val_loss: 0.1019 - val_tp: 57.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 50.0000 - val_accuracy: 0.9683 - val_precision: 0.8261 - val_recall: 0.5327 - val_auc: 0.9318\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1041 - tp: 189.0000 - fp: 61.0000 - tn: 5482.0000 - fn: 133.0000 - accuracy: 0.9669 - precision: 0.7560 - recall: 0.5870 - auc: 0.9282 - val_loss: 0.1013 - val_tp: 58.0000 - val_fp: 15.0000 - val_tn: 1834.0000 - val_fn: 49.0000 - val_accuracy: 0.9673 - val_precision: 0.7945 - val_recall: 0.5421 - val_auc: 0.9340\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1033 - tp: 181.0000 - fp: 54.0000 - tn: 5489.0000 - fn: 141.0000 - accuracy: 0.9668 - precision: 0.7702 - recall: 0.5621 - auc: 0.9288 - val_loss: 0.1013 - val_tp: 64.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 43.0000 - val_accuracy: 0.9688 - val_precision: 0.7805 - val_recall: 0.5981 - val_auc: 0.9404\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1055 - tp: 183.0000 - fp: 59.0000 - tn: 5484.0000 - fn: 139.0000 - accuracy: 0.9662 - precision: 0.7562 - recall: 0.5683 - auc: 0.9274 - val_loss: 0.1017 - val_tp: 66.0000 - val_fp: 19.0000 - val_tn: 1830.0000 - val_fn: 41.0000 - val_accuracy: 0.9693 - val_precision: 0.7765 - val_recall: 0.6168 - val_auc: 0.9382\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1038 - tp: 184.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 138.0000 - accuracy: 0.9674 - precision: 0.7764 - recall: 0.5714 - auc: 0.9274 - val_loss: 0.1029 - val_tp: 56.0000 - val_fp: 10.0000 - val_tn: 1839.0000 - val_fn: 51.0000 - val_accuracy: 0.9688 - val_precision: 0.8485 - val_recall: 0.5234 - val_auc: 0.9321\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1001 - tp: 184.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 138.0000 - accuracy: 0.9685 - precision: 0.7965 - recall: 0.5714 - auc: 0.9307 - val_loss: 0.1006 - val_tp: 60.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 47.0000 - val_accuracy: 0.9688 - val_precision: 0.8108 - val_recall: 0.5607 - val_auc: 0.9381\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1008 - tp: 191.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 131.0000 - accuracy: 0.9686 - precision: 0.7828 - recall: 0.5932 - auc: 0.9313 - val_loss: 0.0999 - val_tp: 62.0000 - val_fp: 15.0000 - val_tn: 1834.0000 - val_fn: 45.0000 - val_accuracy: 0.9693 - val_precision: 0.8052 - val_recall: 0.5794 - val_auc: 0.9426\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1031 - tp: 183.0000 - fp: 59.0000 - tn: 5484.0000 - fn: 139.0000 - accuracy: 0.9662 - precision: 0.7562 - recall: 0.5683 - auc: 0.9296 - val_loss: 0.1052 - val_tp: 53.0000 - val_fp: 8.0000 - val_tn: 1841.0000 - val_fn: 54.0000 - val_accuracy: 0.9683 - val_precision: 0.8689 - val_recall: 0.4953 - val_auc: 0.9348\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1014 - tp: 184.0000 - fp: 56.0000 - tn: 5487.0000 - fn: 138.0000 - accuracy: 0.9669 - precision: 0.7667 - recall: 0.5714 - auc: 0.9346 - val_loss: 0.1011 - val_tp: 58.0000 - val_fp: 11.0000 - val_tn: 1838.0000 - val_fn: 49.0000 - val_accuracy: 0.9693 - val_precision: 0.8406 - val_recall: 0.5421 - val_auc: 0.9354\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0987 - tp: 192.0000 - fp: 46.0000 - tn: 5497.0000 - fn: 130.0000 - accuracy: 0.9700 - precision: 0.8067 - recall: 0.5963 - auc: 0.9374 - val_loss: 0.0997 - val_tp: 60.0000 - val_fp: 16.0000 - val_tn: 1833.0000 - val_fn: 47.0000 - val_accuracy: 0.9678 - val_precision: 0.7895 - val_recall: 0.5607 - val_auc: 0.9393\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1000 - tp: 188.0000 - fp: 49.0000 - tn: 5494.0000 - fn: 134.0000 - accuracy: 0.9688 - precision: 0.7932 - recall: 0.5839 - auc: 0.9334 - val_loss: 0.0994 - val_tp: 63.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 44.0000 - val_accuracy: 0.9688 - val_precision: 0.7875 - val_recall: 0.5888 - val_auc: 0.9384\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0972 - tp: 194.0000 - fp: 51.0000 - tn: 5492.0000 - fn: 128.0000 - accuracy: 0.9695 - precision: 0.7918 - recall: 0.6025 - auc: 0.9409 - val_loss: 0.1100 - val_tp: 45.0000 - val_fp: 6.0000 - val_tn: 1843.0000 - val_fn: 62.0000 - val_accuracy: 0.9652 - val_precision: 0.8824 - val_recall: 0.4206 - val_auc: 0.9416\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0993 - tp: 187.0000 - fp: 55.0000 - tn: 5488.0000 - fn: 135.0000 - accuracy: 0.9676 - precision: 0.7727 - recall: 0.5807 - auc: 0.9383 - val_loss: 0.0998 - val_tp: 57.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 50.0000 - val_accuracy: 0.9683 - val_precision: 0.8261 - val_recall: 0.5327 - val_auc: 0.9388\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0982 - tp: 183.0000 - fp: 57.0000 - tn: 5486.0000 - fn: 139.0000 - accuracy: 0.9666 - precision: 0.7625 - recall: 0.5683 - auc: 0.9354 - val_loss: 0.1009 - val_tp: 70.0000 - val_fp: 21.0000 - val_tn: 1828.0000 - val_fn: 37.0000 - val_accuracy: 0.9703 - val_precision: 0.7692 - val_recall: 0.6542 - val_auc: 0.9431\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0961 - tp: 195.0000 - fp: 55.0000 - tn: 5488.0000 - fn: 127.0000 - accuracy: 0.9690 - precision: 0.7800 - recall: 0.6056 - auc: 0.9425 - val_loss: 0.0996 - val_tp: 58.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 49.0000 - val_accuracy: 0.9678 - val_precision: 0.8056 - val_recall: 0.5421 - val_auc: 0.9386\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0966 - tp: 193.0000 - fp: 51.0000 - tn: 5492.0000 - fn: 129.0000 - accuracy: 0.9693 - precision: 0.7910 - recall: 0.5994 - auc: 0.9382 - val_loss: 0.0992 - val_tp: 57.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 50.0000 - val_accuracy: 0.9683 - val_precision: 0.8261 - val_recall: 0.5327 - val_auc: 0.9416\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0974 - tp: 190.0000 - fp: 50.0000 - tn: 5493.0000 - fn: 132.0000 - accuracy: 0.9690 - precision: 0.7917 - recall: 0.5901 - auc: 0.9368 - val_loss: 0.1000 - val_tp: 57.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 50.0000 - val_accuracy: 0.9683 - val_precision: 0.8261 - val_recall: 0.5327 - val_auc: 0.9400\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0971 - tp: 192.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 130.0000 - accuracy: 0.9688 - precision: 0.7837 - recall: 0.5963 - auc: 0.9368 - val_loss: 0.0987 - val_tp: 60.0000 - val_fp: 13.0000 - val_tn: 1836.0000 - val_fn: 47.0000 - val_accuracy: 0.9693 - val_precision: 0.8219 - val_recall: 0.5607 - val_auc: 0.9406\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0975 - tp: 193.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 129.0000 - accuracy: 0.9691 - precision: 0.7878 - recall: 0.5994 - auc: 0.9413 - val_loss: 0.0985 - val_tp: 57.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 50.0000 - val_accuracy: 0.9673 - val_precision: 0.8028 - val_recall: 0.5327 - val_auc: 0.9440\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0952 - tp: 197.0000 - fp: 48.0000 - tn: 5495.0000 - fn: 125.0000 - accuracy: 0.9705 - precision: 0.8041 - recall: 0.6118 - auc: 0.9369 - val_loss: 0.0995 - val_tp: 55.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 52.0000 - val_accuracy: 0.9673 - val_precision: 0.8209 - val_recall: 0.5140 - val_auc: 0.9424\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0938 - tp: 194.0000 - fp: 55.0000 - tn: 5488.0000 - fn: 128.0000 - accuracy: 0.9688 - precision: 0.7791 - recall: 0.6025 - auc: 0.9473 - val_loss: 0.0980 - val_tp: 57.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 50.0000 - val_accuracy: 0.9683 - val_precision: 0.8261 - val_recall: 0.5327 - val_auc: 0.9432\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0953 - tp: 194.0000 - fp: 49.0000 - tn: 5494.0000 - fn: 128.0000 - accuracy: 0.9698 - precision: 0.7984 - recall: 0.6025 - auc: 0.9406 - val_loss: 0.0972 - val_tp: 61.0000 - val_fp: 15.0000 - val_tn: 1834.0000 - val_fn: 46.0000 - val_accuracy: 0.9688 - val_precision: 0.8026 - val_recall: 0.5701 - val_auc: 0.9438\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0938 - tp: 200.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 122.0000 - accuracy: 0.9702 - precision: 0.7905 - recall: 0.6211 - auc: 0.9448 - val_loss: 0.0990 - val_tp: 56.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 51.0000 - val_accuracy: 0.9678 - val_precision: 0.8235 - val_recall: 0.5234 - val_auc: 0.9430\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0940 - tp: 192.0000 - fp: 47.0000 - tn: 5496.0000 - fn: 130.0000 - accuracy: 0.9698 - precision: 0.8033 - recall: 0.5963 - auc: 0.9429 - val_loss: 0.0971 - val_tp: 65.0000 - val_fp: 19.0000 - val_tn: 1830.0000 - val_fn: 42.0000 - val_accuracy: 0.9688 - val_precision: 0.7738 - val_recall: 0.6075 - val_auc: 0.9438\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0926 - tp: 198.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 124.0000 - accuracy: 0.9714 - precision: 0.8182 - recall: 0.6149 - auc: 0.9434 - val_loss: 0.0990 - val_tp: 56.0000 - val_fp: 11.0000 - val_tn: 1838.0000 - val_fn: 51.0000 - val_accuracy: 0.9683 - val_precision: 0.8358 - val_recall: 0.5234 - val_auc: 0.9467\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0914 - tp: 204.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 118.0000 - accuracy: 0.9708 - precision: 0.7938 - recall: 0.6335 - auc: 0.9488 - val_loss: 0.0962 - val_tp: 61.0000 - val_fp: 16.0000 - val_tn: 1833.0000 - val_fn: 46.0000 - val_accuracy: 0.9683 - val_precision: 0.7922 - val_recall: 0.5701 - val_auc: 0.9453\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0929 - tp: 200.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 122.0000 - accuracy: 0.9702 - precision: 0.7905 - recall: 0.6211 - auc: 0.9507 - val_loss: 0.0966 - val_tp: 61.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 46.0000 - val_accuracy: 0.9693 - val_precision: 0.8133 - val_recall: 0.5701 - val_auc: 0.9464\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0926 - tp: 201.0000 - fp: 51.0000 - tn: 5492.0000 - fn: 121.0000 - accuracy: 0.9707 - precision: 0.7976 - recall: 0.6242 - auc: 0.9467 - val_loss: 0.0970 - val_tp: 58.0000 - val_fp: 11.0000 - val_tn: 1838.0000 - val_fn: 49.0000 - val_accuracy: 0.9693 - val_precision: 0.8406 - val_recall: 0.5421 - val_auc: 0.9480\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0927 - tp: 194.0000 - fp: 48.0000 - tn: 5495.0000 - fn: 128.0000 - accuracy: 0.9700 - precision: 0.8017 - recall: 0.6025 - auc: 0.9454 - val_loss: 0.0973 - val_tp: 60.0000 - val_fp: 10.0000 - val_tn: 1839.0000 - val_fn: 47.0000 - val_accuracy: 0.9709 - val_precision: 0.8571 - val_recall: 0.5607 - val_auc: 0.9437\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0900 - tp: 198.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 124.0000 - accuracy: 0.9714 - precision: 0.8182 - recall: 0.6149 - auc: 0.9494 - val_loss: 0.0967 - val_tp: 58.0000 - val_fp: 11.0000 - val_tn: 1838.0000 - val_fn: 49.0000 - val_accuracy: 0.9693 - val_precision: 0.8406 - val_recall: 0.5421 - val_auc: 0.9464\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0913 - tp: 198.0000 - fp: 48.0000 - tn: 5495.0000 - fn: 124.0000 - accuracy: 0.9707 - precision: 0.8049 - recall: 0.6149 - auc: 0.9461 - val_loss: 0.0955 - val_tp: 65.0000 - val_fp: 19.0000 - val_tn: 1830.0000 - val_fn: 42.0000 - val_accuracy: 0.9688 - val_precision: 0.7738 - val_recall: 0.6075 - val_auc: 0.9452\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0891 - tp: 199.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 123.0000 - accuracy: 0.9702 - precision: 0.7928 - recall: 0.6180 - auc: 0.9477 - val_loss: 0.1007 - val_tp: 52.0000 - val_fp: 8.0000 - val_tn: 1841.0000 - val_fn: 55.0000 - val_accuracy: 0.9678 - val_precision: 0.8667 - val_recall: 0.4860 - val_auc: 0.9471\n",
            "The model is better than a simple constant model for sure:\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 0.5652 - tp: 58.0000 - fp: 86.0000 - tn: 7306.0000 - fn: 371.0000 - accuracy: 0.9416 - precision: 0.4028 - recall: 0.1352 - auc: 0.5112 - val_loss: 0.4096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0876\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.3567 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5543.0000 - fn: 322.0000 - accuracy: 0.9451 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1182 - val_loss: 0.3135 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0916\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.2660 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5543.0000 - fn: 322.0000 - accuracy: 0.9451 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2459 - val_loss: 0.2025 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1849.0000 - val_fn: 107.0000 - val_accuracy: 0.9453 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7254\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1653 - tp: 11.0000 - fp: 3.0000 - tn: 5540.0000 - fn: 311.0000 - accuracy: 0.9465 - precision: 0.7857 - recall: 0.0342 - auc: 0.8610 - val_loss: 0.1316 - val_tp: 23.0000 - val_fp: 1.0000 - val_tn: 1848.0000 - val_fn: 84.0000 - val_accuracy: 0.9565 - val_precision: 0.9583 - val_recall: 0.2150 - val_auc: 0.9130\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1247 - tp: 93.0000 - fp: 32.0000 - tn: 5511.0000 - fn: 229.0000 - accuracy: 0.9555 - precision: 0.7440 - recall: 0.2888 - auc: 0.9178 - val_loss: 0.1190 - val_tp: 49.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 58.0000 - val_accuracy: 0.9611 - val_precision: 0.7313 - val_recall: 0.4579 - val_auc: 0.9203\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1147 - tp: 139.0000 - fp: 50.0000 - tn: 5493.0000 - fn: 183.0000 - accuracy: 0.9603 - precision: 0.7354 - recall: 0.4317 - auc: 0.9283 - val_loss: 0.1143 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 50.0000 - val_accuracy: 0.9657 - val_precision: 0.7703 - val_recall: 0.5327 - val_auc: 0.9187\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1117 - tp: 158.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 164.0000 - accuracy: 0.9630 - precision: 0.7488 - recall: 0.4907 - auc: 0.9278 - val_loss: 0.1131 - val_tp: 58.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 49.0000 - val_accuracy: 0.9657 - val_precision: 0.7632 - val_recall: 0.5421 - val_auc: 0.9192\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1108 - tp: 157.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 165.0000 - accuracy: 0.9630 - precision: 0.7512 - recall: 0.4876 - auc: 0.9307 - val_loss: 0.1124 - val_tp: 54.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 53.0000 - val_accuracy: 0.9637 - val_precision: 0.7500 - val_recall: 0.5047 - val_auc: 0.9185\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1104 - tp: 171.0000 - fp: 57.0000 - tn: 5486.0000 - fn: 151.0000 - accuracy: 0.9645 - precision: 0.7500 - recall: 0.5311 - auc: 0.9274 - val_loss: 0.1109 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 50.0000 - val_accuracy: 0.9657 - val_precision: 0.7703 - val_recall: 0.5327 - val_auc: 0.9221\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1070 - tp: 167.0000 - fp: 56.0000 - tn: 5487.0000 - fn: 155.0000 - accuracy: 0.9640 - precision: 0.7489 - recall: 0.5186 - auc: 0.9354 - val_loss: 0.1112 - val_tp: 58.0000 - val_fp: 19.0000 - val_tn: 1830.0000 - val_fn: 49.0000 - val_accuracy: 0.9652 - val_precision: 0.7532 - val_recall: 0.5421 - val_auc: 0.9198\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1076 - tp: 181.0000 - fp: 62.0000 - tn: 5481.0000 - fn: 141.0000 - accuracy: 0.9654 - precision: 0.7449 - recall: 0.5621 - auc: 0.9289 - val_loss: 0.1097 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 50.0000 - val_accuracy: 0.9657 - val_precision: 0.7703 - val_recall: 0.5327 - val_auc: 0.9246\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1050 - tp: 177.0000 - fp: 55.0000 - tn: 5488.0000 - fn: 145.0000 - accuracy: 0.9659 - precision: 0.7629 - recall: 0.5497 - auc: 0.9405 - val_loss: 0.1091 - val_tp: 55.0000 - val_fp: 15.0000 - val_tn: 1834.0000 - val_fn: 52.0000 - val_accuracy: 0.9657 - val_precision: 0.7857 - val_recall: 0.5140 - val_auc: 0.9247\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1068 - tp: 168.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 154.0000 - accuracy: 0.9649 - precision: 0.7636 - recall: 0.5217 - auc: 0.9339 - val_loss: 0.1084 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 50.0000 - val_accuracy: 0.9657 - val_precision: 0.7703 - val_recall: 0.5327 - val_auc: 0.9262\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1041 - tp: 172.0000 - fp: 48.0000 - tn: 5495.0000 - fn: 150.0000 - accuracy: 0.9662 - precision: 0.7818 - recall: 0.5342 - auc: 0.9392 - val_loss: 0.1084 - val_tp: 61.0000 - val_fp: 22.0000 - val_tn: 1827.0000 - val_fn: 46.0000 - val_accuracy: 0.9652 - val_precision: 0.7349 - val_recall: 0.5701 - val_auc: 0.9258\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1059 - tp: 174.0000 - fp: 56.0000 - tn: 5487.0000 - fn: 148.0000 - accuracy: 0.9652 - precision: 0.7565 - recall: 0.5404 - auc: 0.9394 - val_loss: 0.1076 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 1834.0000 - val_fn: 50.0000 - val_accuracy: 0.9668 - val_precision: 0.7917 - val_recall: 0.5327 - val_auc: 0.9265\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1019 - tp: 185.0000 - fp: 57.0000 - tn: 5486.0000 - fn: 137.0000 - accuracy: 0.9669 - precision: 0.7645 - recall: 0.5745 - auc: 0.9367 - val_loss: 0.1072 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 1830.0000 - val_fn: 47.0000 - val_accuracy: 0.9663 - val_precision: 0.7595 - val_recall: 0.5607 - val_auc: 0.9259\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1004 - tp: 187.0000 - fp: 60.0000 - tn: 5483.0000 - fn: 135.0000 - accuracy: 0.9668 - precision: 0.7571 - recall: 0.5807 - auc: 0.9429 - val_loss: 0.1068 - val_tp: 57.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 50.0000 - val_accuracy: 0.9657 - val_precision: 0.7703 - val_recall: 0.5327 - val_auc: 0.9286\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1019 - tp: 180.0000 - fp: 50.0000 - tn: 5493.0000 - fn: 142.0000 - accuracy: 0.9673 - precision: 0.7826 - recall: 0.5590 - auc: 0.9387 - val_loss: 0.1058 - val_tp: 61.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 46.0000 - val_accuracy: 0.9673 - val_precision: 0.7722 - val_recall: 0.5701 - val_auc: 0.9282\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1016 - tp: 179.0000 - fp: 57.0000 - tn: 5486.0000 - fn: 143.0000 - accuracy: 0.9659 - precision: 0.7585 - recall: 0.5559 - auc: 0.9406 - val_loss: 0.1085 - val_tp: 68.0000 - val_fp: 27.0000 - val_tn: 1822.0000 - val_fn: 39.0000 - val_accuracy: 0.9663 - val_precision: 0.7158 - val_recall: 0.6355 - val_auc: 0.9309\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0998 - tp: 187.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 135.0000 - accuracy: 0.9679 - precision: 0.7792 - recall: 0.5807 - auc: 0.9446 - val_loss: 0.1045 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 1833.0000 - val_fn: 48.0000 - val_accuracy: 0.9673 - val_precision: 0.7867 - val_recall: 0.5514 - val_auc: 0.9300\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1014 - tp: 186.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 136.0000 - accuracy: 0.9679 - precision: 0.7815 - recall: 0.5776 - auc: 0.9408 - val_loss: 0.1045 - val_tp: 58.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 49.0000 - val_accuracy: 0.9663 - val_precision: 0.7733 - val_recall: 0.5421 - val_auc: 0.9290\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.1007 - tp: 181.0000 - fp: 57.0000 - tn: 5486.0000 - fn: 141.0000 - accuracy: 0.9662 - precision: 0.7605 - recall: 0.5621 - auc: 0.9398 - val_loss: 0.1036 - val_tp: 59.0000 - val_fp: 16.0000 - val_tn: 1833.0000 - val_fn: 48.0000 - val_accuracy: 0.9673 - val_precision: 0.7867 - val_recall: 0.5514 - val_auc: 0.9319\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0988 - tp: 181.0000 - fp: 61.0000 - tn: 5482.0000 - fn: 141.0000 - accuracy: 0.9656 - precision: 0.7479 - recall: 0.5621 - auc: 0.9435 - val_loss: 0.1048 - val_tp: 57.0000 - val_fp: 15.0000 - val_tn: 1834.0000 - val_fn: 50.0000 - val_accuracy: 0.9668 - val_precision: 0.7917 - val_recall: 0.5327 - val_auc: 0.9336\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0995 - tp: 187.0000 - fp: 56.0000 - tn: 5487.0000 - fn: 135.0000 - accuracy: 0.9674 - precision: 0.7695 - recall: 0.5807 - auc: 0.9404 - val_loss: 0.1083 - val_tp: 71.0000 - val_fp: 27.0000 - val_tn: 1822.0000 - val_fn: 36.0000 - val_accuracy: 0.9678 - val_precision: 0.7245 - val_recall: 0.6636 - val_auc: 0.9342\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0984 - tp: 189.0000 - fp: 59.0000 - tn: 5484.0000 - fn: 133.0000 - accuracy: 0.9673 - precision: 0.7621 - recall: 0.5870 - auc: 0.9441 - val_loss: 0.1052 - val_tp: 54.0000 - val_fp: 12.0000 - val_tn: 1837.0000 - val_fn: 53.0000 - val_accuracy: 0.9668 - val_precision: 0.8182 - val_recall: 0.5047 - val_auc: 0.9304\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0941 - tp: 189.0000 - fp: 54.0000 - tn: 5489.0000 - fn: 133.0000 - accuracy: 0.9681 - precision: 0.7778 - recall: 0.5870 - auc: 0.9528 - val_loss: 0.1029 - val_tp: 63.0000 - val_fp: 22.0000 - val_tn: 1827.0000 - val_fn: 44.0000 - val_accuracy: 0.9663 - val_precision: 0.7412 - val_recall: 0.5888 - val_auc: 0.9311\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0965 - tp: 191.0000 - fp: 50.0000 - tn: 5493.0000 - fn: 131.0000 - accuracy: 0.9691 - precision: 0.7925 - recall: 0.5932 - auc: 0.9467 - val_loss: 0.1038 - val_tp: 60.0000 - val_fp: 21.0000 - val_tn: 1828.0000 - val_fn: 47.0000 - val_accuracy: 0.9652 - val_precision: 0.7407 - val_recall: 0.5607 - val_auc: 0.9324\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0967 - tp: 189.0000 - fp: 55.0000 - tn: 5488.0000 - fn: 133.0000 - accuracy: 0.9679 - precision: 0.7746 - recall: 0.5870 - auc: 0.9463 - val_loss: 0.1106 - val_tp: 45.0000 - val_fp: 8.0000 - val_tn: 1841.0000 - val_fn: 62.0000 - val_accuracy: 0.9642 - val_precision: 0.8491 - val_recall: 0.4206 - val_auc: 0.9214\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0984 - tp: 186.0000 - fp: 63.0000 - tn: 5480.0000 - fn: 136.0000 - accuracy: 0.9661 - precision: 0.7470 - recall: 0.5776 - auc: 0.9448 - val_loss: 0.1018 - val_tp: 60.0000 - val_fp: 17.0000 - val_tn: 1832.0000 - val_fn: 47.0000 - val_accuracy: 0.9673 - val_precision: 0.7792 - val_recall: 0.5607 - val_auc: 0.9361\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0957 - tp: 187.0000 - fp: 54.0000 - tn: 5489.0000 - fn: 135.0000 - accuracy: 0.9678 - precision: 0.7759 - recall: 0.5807 - auc: 0.9476 - val_loss: 0.1018 - val_tp: 60.0000 - val_fp: 19.0000 - val_tn: 1830.0000 - val_fn: 47.0000 - val_accuracy: 0.9663 - val_precision: 0.7595 - val_recall: 0.5607 - val_auc: 0.9328\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0973 - tp: 183.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 139.0000 - accuracy: 0.9673 - precision: 0.7754 - recall: 0.5683 - auc: 0.9472 - val_loss: 0.1019 - val_tp: 65.0000 - val_fp: 23.0000 - val_tn: 1826.0000 - val_fn: 42.0000 - val_accuracy: 0.9668 - val_precision: 0.7386 - val_recall: 0.6075 - val_auc: 0.9342\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0951 - tp: 188.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 134.0000 - accuracy: 0.9681 - precision: 0.7801 - recall: 0.5839 - auc: 0.9458 - val_loss: 0.1015 - val_tp: 64.0000 - val_fp: 22.0000 - val_tn: 1827.0000 - val_fn: 43.0000 - val_accuracy: 0.9668 - val_precision: 0.7442 - val_recall: 0.5981 - val_auc: 0.9360\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0944 - tp: 190.0000 - fp: 51.0000 - tn: 5492.0000 - fn: 132.0000 - accuracy: 0.9688 - precision: 0.7884 - recall: 0.5901 - auc: 0.9492 - val_loss: 0.1035 - val_tp: 70.0000 - val_fp: 26.0000 - val_tn: 1823.0000 - val_fn: 37.0000 - val_accuracy: 0.9678 - val_precision: 0.7292 - val_recall: 0.6542 - val_auc: 0.9332\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0940 - tp: 187.0000 - fp: 58.0000 - tn: 5485.0000 - fn: 135.0000 - accuracy: 0.9671 - precision: 0.7633 - recall: 0.5807 - auc: 0.9464 - val_loss: 0.1007 - val_tp: 64.0000 - val_fp: 22.0000 - val_tn: 1827.0000 - val_fn: 43.0000 - val_accuracy: 0.9668 - val_precision: 0.7442 - val_recall: 0.5981 - val_auc: 0.9351\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0937 - tp: 191.0000 - fp: 56.0000 - tn: 5487.0000 - fn: 131.0000 - accuracy: 0.9681 - precision: 0.7733 - recall: 0.5932 - auc: 0.9508 - val_loss: 0.1024 - val_tp: 69.0000 - val_fp: 26.0000 - val_tn: 1823.0000 - val_fn: 38.0000 - val_accuracy: 0.9673 - val_precision: 0.7263 - val_recall: 0.6449 - val_auc: 0.9346\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0915 - tp: 193.0000 - fp: 48.0000 - tn: 5495.0000 - fn: 129.0000 - accuracy: 0.9698 - precision: 0.8008 - recall: 0.5994 - auc: 0.9560 - val_loss: 0.1050 - val_tp: 73.0000 - val_fp: 28.0000 - val_tn: 1821.0000 - val_fn: 34.0000 - val_accuracy: 0.9683 - val_precision: 0.7228 - val_recall: 0.6822 - val_auc: 0.9372\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0927 - tp: 196.0000 - fp: 55.0000 - tn: 5488.0000 - fn: 126.0000 - accuracy: 0.9691 - precision: 0.7809 - recall: 0.6087 - auc: 0.9494 - val_loss: 0.1051 - val_tp: 73.0000 - val_fp: 30.0000 - val_tn: 1819.0000 - val_fn: 34.0000 - val_accuracy: 0.9673 - val_precision: 0.7087 - val_recall: 0.6822 - val_auc: 0.9384\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0913 - tp: 193.0000 - fp: 54.0000 - tn: 5489.0000 - fn: 129.0000 - accuracy: 0.9688 - precision: 0.7814 - recall: 0.5994 - auc: 0.9539 - val_loss: 0.0996 - val_tp: 63.0000 - val_fp: 20.0000 - val_tn: 1829.0000 - val_fn: 44.0000 - val_accuracy: 0.9673 - val_precision: 0.7590 - val_recall: 0.5888 - val_auc: 0.9391\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0896 - tp: 194.0000 - fp: 56.0000 - tn: 5487.0000 - fn: 128.0000 - accuracy: 0.9686 - precision: 0.7760 - recall: 0.6025 - auc: 0.9564 - val_loss: 0.0995 - val_tp: 62.0000 - val_fp: 14.0000 - val_tn: 1835.0000 - val_fn: 45.0000 - val_accuracy: 0.9698 - val_precision: 0.8158 - val_recall: 0.5794 - val_auc: 0.9384\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0903 - tp: 195.0000 - fp: 49.0000 - tn: 5494.0000 - fn: 127.0000 - accuracy: 0.9700 - precision: 0.7992 - recall: 0.6056 - auc: 0.9534 - val_loss: 0.0995 - val_tp: 69.0000 - val_fp: 24.0000 - val_tn: 1825.0000 - val_fn: 38.0000 - val_accuracy: 0.9683 - val_precision: 0.7419 - val_recall: 0.6449 - val_auc: 0.9386\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0900 - tp: 205.0000 - fp: 51.0000 - tn: 5492.0000 - fn: 117.0000 - accuracy: 0.9714 - precision: 0.8008 - recall: 0.6366 - auc: 0.9530 - val_loss: 0.1001 - val_tp: 58.0000 - val_fp: 13.0000 - val_tn: 1836.0000 - val_fn: 49.0000 - val_accuracy: 0.9683 - val_precision: 0.8169 - val_recall: 0.5421 - val_auc: 0.9359\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0901 - tp: 199.0000 - fp: 49.0000 - tn: 5494.0000 - fn: 123.0000 - accuracy: 0.9707 - precision: 0.8024 - recall: 0.6180 - auc: 0.9510 - val_loss: 0.0987 - val_tp: 69.0000 - val_fp: 24.0000 - val_tn: 1825.0000 - val_fn: 38.0000 - val_accuracy: 0.9683 - val_precision: 0.7419 - val_recall: 0.6449 - val_auc: 0.9379\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0899 - tp: 201.0000 - fp: 46.0000 - tn: 5497.0000 - fn: 121.0000 - accuracy: 0.9715 - precision: 0.8138 - recall: 0.6242 - auc: 0.9550 - val_loss: 0.0988 - val_tp: 69.0000 - val_fp: 25.0000 - val_tn: 1824.0000 - val_fn: 38.0000 - val_accuracy: 0.9678 - val_precision: 0.7340 - val_recall: 0.6449 - val_auc: 0.9387\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0901 - tp: 197.0000 - fp: 53.0000 - tn: 5490.0000 - fn: 125.0000 - accuracy: 0.9697 - precision: 0.7880 - recall: 0.6118 - auc: 0.9550 - val_loss: 0.0978 - val_tp: 63.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 44.0000 - val_accuracy: 0.9683 - val_precision: 0.7778 - val_recall: 0.5888 - val_auc: 0.9422\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0886 - tp: 198.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 124.0000 - accuracy: 0.9714 - precision: 0.8182 - recall: 0.6149 - auc: 0.9555 - val_loss: 0.0979 - val_tp: 68.0000 - val_fp: 25.0000 - val_tn: 1824.0000 - val_fn: 39.0000 - val_accuracy: 0.9673 - val_precision: 0.7312 - val_recall: 0.6355 - val_auc: 0.9420\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0892 - tp: 197.0000 - fp: 44.0000 - tn: 5499.0000 - fn: 125.0000 - accuracy: 0.9712 - precision: 0.8174 - recall: 0.6118 - auc: 0.9545 - val_loss: 0.1016 - val_tp: 68.0000 - val_fp: 27.0000 - val_tn: 1822.0000 - val_fn: 39.0000 - val_accuracy: 0.9663 - val_precision: 0.7158 - val_recall: 0.6355 - val_auc: 0.9371\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0875 - tp: 209.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 113.0000 - accuracy: 0.9719 - precision: 0.8008 - recall: 0.6491 - auc: 0.9582 - val_loss: 0.0973 - val_tp: 66.0000 - val_fp: 20.0000 - val_tn: 1829.0000 - val_fn: 41.0000 - val_accuracy: 0.9688 - val_precision: 0.7674 - val_recall: 0.6168 - val_auc: 0.9439\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0878 - tp: 201.0000 - fp: 52.0000 - tn: 5491.0000 - fn: 121.0000 - accuracy: 0.9705 - precision: 0.7945 - recall: 0.6242 - auc: 0.9551 - val_loss: 0.0967 - val_tp: 67.0000 - val_fp: 23.0000 - val_tn: 1826.0000 - val_fn: 40.0000 - val_accuracy: 0.9678 - val_precision: 0.7444 - val_recall: 0.6262 - val_auc: 0.9435\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0863 - tp: 206.0000 - fp: 51.0000 - tn: 5492.0000 - fn: 116.0000 - accuracy: 0.9715 - precision: 0.8016 - recall: 0.6398 - auc: 0.9567 - val_loss: 0.0964 - val_tp: 66.0000 - val_fp: 18.0000 - val_tn: 1831.0000 - val_fn: 41.0000 - val_accuracy: 0.9698 - val_precision: 0.7857 - val_recall: 0.6168 - val_auc: 0.9443\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.0871 - tp: 200.0000 - fp: 46.0000 - tn: 5497.0000 - fn: 122.0000 - accuracy: 0.9714 - precision: 0.8130 - recall: 0.6211 - auc: 0.9562 - val_loss: 0.1006 - val_tp: 73.0000 - val_fp: 31.0000 - val_tn: 1818.0000 - val_fn: 34.0000 - val_accuracy: 0.9668 - val_precision: 0.7019 - val_recall: 0.6822 - val_auc: 0.9450\n",
            "The model is better than a simple constant model for sure:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0wqe2ArzCej",
        "outputId": "367250a0-0e74-4b8d-8f73-ad6894f565b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "tf.saved_model.save(model,'/content/drive/My Drive/final_model/my_model') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/final_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl6QZjvU3ful",
        "outputId": "f131102f-6742-48ca-82bd-d1c34bcf7484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9550344944000244, 0.9487901926040649, 0.9549775719642639]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMuBcNSL3hkQ",
        "outputId": "602a6ab5-ffa8-4b3f-9807-374a4bb4f67a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9569734930992126, 0.9453480839729309, 0.942166268825531]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we8UKquX2nYF",
        "outputId": "7349b76b-e4f5-4386-ffdd-1f620c06b1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'][5:], color ='blue')\n",
        "plt.plot(history.history['val_accuracy'][5:], color ='orange')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f471af5df28>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDunN09ovN0O",
        "outputId": "a9467165-de39-4ffd-af11-7953f67cda4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot(history.history['auc'][5:], color ='blue')\n",
        "plt.plot(history.history['val_auc'][5:], color ='orange')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f47e710a400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwRIl1uCgig_"
      },
      "source": [
        "loaded_model = tf.keras.models.load_model('/content/drive/My Drive/final_model/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YSW3gX-U6VF"
      },
      "source": [
        "pr = loaded_model.predict(X, batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3qtHOthVwZb",
        "outputId": "3d8ec28e-16ab-46df-bf95-32c230a7fe35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y,pr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9827366446684629"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4adKq41Wb0p"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/drive/My Drive/final_model/my_model') # path to the SavedModel directory\n",
        "converter.allow_custom_ops = True\n",
        "tflite_model = converter.convert()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akNPgzP5XMsr"
      },
      "source": [
        "with open('/content/drive/My Drive/final_model/model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-47-QNsnXxQA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}